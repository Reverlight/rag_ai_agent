from openai import OpenAI
from llama_index.readers.file import PDFReader
from llama_index.core.node_parser import SentenceSplitter
from dotenv import load_dotenv

load_dotenv()

client = OpenAI()
EMBEDED_MODEL = 'text-embedding-3-large'
EMBEDED_DIM = 3072

splitter = SentenceSplitter(chunk_size=1000, chunk_overlap=200)


def load_and_chunk_pdf(path: str):
    docs = PDFReader().load_data(file=path)
    texts = [d.text for d in docs if getattr(d, 'text', None)]
    chunks = []
    for t in texts:
        chunks.extend(splitter.split_texts(t))
    return chunks


def embed_texts(texts):
    response = client.embeddings.create(
        model=EMBEDED_MODEL,
        input=texts
    )
    return [item.embedding for item in response.data]